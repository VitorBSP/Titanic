---
title: "Você sobreviveria ao Titanic?"
author: "Eu, Vítor Pereira, não."
header-includes:
   - \usepackage[brazil]{babel}
   - \usepackage{bm}
geometry: left=1.7cm, right=1.7cm, top=3.33cm, bottom=3.2cm
output:
  bookdown::pdf_document2:
editor_options:
  chunk_output_type: console
indent: true
---



```{r setup,include=F}
options(digits=3)  #Arrendodamento
options(scipen=999)
ggplot2::theme_set(ggplot2::theme_minimal()) #Tema dos gráficos produzidos no ggplot2
knitr::opts_chunk$set(echo=F,message=F,warning=F,fig.pos = 'H',fig.align = 'center',fig.width=7.8, fig.height=4.85)
scale_fill_discrete = \(...) ggplot2::scale_fill_brewer(... , palette="Set2") #Fixa a scale do fill dos gráficos do ggplot2
library(tidyverse)
library(tidymodels)
library(probably)
library(patchwork)
class_metrics <- metric_set(accuracy, kap, precision, sensitivity, specificity)#, roc_auc)


```

```{r functions}
set.seed(123)
d=function(df,v1,v2,px){
  df %>% 
    ggplot(aes({{v1}},{{v2}})) +
    geom_point(size=2.1,color="red")+
    ggrepel::geom_text_repel(aes(label=n),size=2.8,point.padding = 0.3)
}
graph<-function(df,l){
  df %>% 
    as_tibble() %>% 
      ggplot(aes(as.numeric(row.names(df  %>% as_tibble())),value))+
      geom_point(color = 'black')+
      geom_hline(yintercept=l, linetype="dashed", color = "red")+
      geom_hline(yintercept=-l, linetype="dashed", color = "red")+
      labs(x="Índice")
    
}
fit2df<-function(fit) {
  summary(fit) |>
    (\(x) x$coefficients)() |>
    data.frame() |>
    round(3) |>
    mutate(P.valor = ifelse(
      `Pr...t..` < 0.001,"<0.001*",
      ifelse(`Pr...t..` < 0.05, paste0(`Pr...t..`, '*', sep = ''), `Pr...t..`))) |>
    select(-`Pr...t..`,
      "Estimativa" = "Estimate",
      "Desvio padrão" = "Std..Error",
      "Estatística t" = "t.value"
    )
}
dffts1<-function(fitn,lab1){
  n = length(fitn$fitted.values)
  dffits(fitn) %>% 
 graph(2*sqrt(fitn$rank / n))+
  labs(title={{lab1}},y="DFfits")
}
resid1<-function(residuon,lab1){
 residuon %>% 
  graph(3)+
  geom_hline(yintercept = 0, linetype="dotted", color = "red")+
  labs(title={{lab1}},y="Resíduo")
}
cook1<-function(fitn,lab1){
    n = length(fitn$fitted.values)
  cooks.distance(fitn) %>% 
  graph(4/(n-fitn$rank ))+
  labs(title={{lab1}},y="Distância de Cook")
}

alavanca1 <- function(fit){
  h_bar=fit$rank/length(fit$fitted.values)
  hatvalues(fit) %>%
  graph(3*h_bar)+
  labs(title="Alavancagem",y="Medida de Alavancagem")
}

```

```{r}
df <- read_csv("Base de dados.csv")
df <- df %>% 
  mutate(Sex = factor(Sex, unique(Sex)), Pclass = factor(Pclass, unique(Pclass)),
                    Survived = factor(Survived, unique(Survived))) %>% 
  drop_na(Sex, Pclass, Survived, Age)
```

# Introdução
Neste trabalho iremos relembrar uma das maiores tragédias  da história, Titanic, em 1912, provavelmente o desastre marítimos mais conhecidos da história. Assim, por meio desse trabalho pretendemos simular situações em que pessoas da atualidade fossem transportadas para a época do desastre, elas sobreviveriam ao Titanic? Utilizando regressão logística podemos prever a chance que qualquer pessoa teria de sobreviver à tragédia, assim utilizaremos alguns modelos para tentar garantir o máximo de confiabilidade possível.


# Modelagem
Começaremos com dois modelos de regressão logística, um modelo utilizando a engine `glm`, muito conhecida e utilizada para realização de modelos inferenciais e a engine `glmnet` muito utilizada para modelos preditivos de aprendizado de máquina.

## Dados de teste e treino
Realizamos a divisão da base de dados completa em outras duas: Dados de treino e Dados de teste, para assim pode verificar se os modelos propostos são bons para previsão fora da amostra, sem problemas de __overfitting__ e __underfitting__. Assim obtivemos as seguintes medidas para os dados de teste utilizando os modelos ajustados com os dados de treino:

```{r}
data_split <- initial_split(df, prop = 3/4)
df_train <- training(data_split)
df_test  <- testing(data_split)

recipe_titanic <- recipe(Survived ~ ., data = df) %>% 
  update_role(PassengerId, Name, SibSp, Parch, Ticket, Fare, Cabin, Embarked, new_role = "ID") %>% 
  step_dummy(all_nominal_predictors())
#recipe_titanic1 <- recipe(Survived ~ ., data = df_train) %>% 
#  update_role(PassengerId, Name, SibSp, Parch, Ticket, Fare, Cabin, Embarked, new_role = #"ID") %>% 
#  step_dummy(Sex, Pclass,one_hot = T)

eng_log <- logistic_reg() %>% 
  set_engine("glm")
eng_lognet <- logistic_reg(penalty = double(1), mixture = double(1)) %>% 
  set_engine("glmnet")

df_work=workflow_set(list(recipe_dummies=recipe_titanic),
                     list(logistic=eng_log, logistic_net = eng_lognet),cross=T)
fit1=df_work %>% 
  extract_workflow("recipe_dummies_logistic") %>% 
  fit(data = df_train)
fit2=df_work %>% 
  extract_workflow("recipe_dummies_logistic_net") %>%
  fit(data = df_train)
```

```{r}
fit1 %>%
  extract_fit_parsnip() %>% 
  tidy() %>%
  mypdf1::pdf1_tbl('Estatísticas do Modelo 1 ajustado com os dados de treino')
```
Percebemos que esse modelo é um modelo de regressão logística comum, em que conseguimos obter erro padrão, estatística e p-valores, podendo fazer uma robusta análise inferencial.

```{r}
fit2 %>%
  extract_fit_parsnip() %>% 
  tidy() %>%
  mypdf1::pdf1_tbl('Estatísticas do Modelo 2 ajustado com os dados de treino')
```
Ao contrário do modelo de cima, esse é um modelo focado para previsão dos dados, envolvendo mais técnicas de aprendizado de máquina, assim não podemos realizar a análise inferencial.

```{r}
#glance(final_fit)

ft1 <- fit1 %>%  
  predict(new_data = df_test, type = "prob") %>% 
  bind_cols(df_test)

fit1_metrics <- ft1 %>%
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_0, 
      levels = levels(Survived), 
      threshold = 0.5,
    )
  ) 

class_metrics(fit1_metrics, truth=Survived, estimate=.pred) %>% select(-.estimator) %>%
  mypdf1::pdf1_tbl('Métricas de Avaliação do Modelo 1 nos Dados de Treino')
```

```{r}
#glance(final_fit)

ft2 <- fit2 %>%  
  predict(new_data = df_test, type = "prob") %>% 
  bind_cols(df_test)

fit2_metrics <- ft2 %>%
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_0, 
      levels = levels(Survived), 
      threshold = 0.5,
    )
  ) 

class_metrics(fit2_metrics, truth=Survived, estimate=.pred) %>% select(-.estimator) %>%
  mypdf1::pdf1_tbl('Métricas de Avaliação do Modelo 2 nos Dados de Treino')
```
Percebemos que as métricas nos dois Modelos são muito próximas, porém o Modelo 1 que utiliza a engina glm padrão, Precisão e Especificidade e o Kappa de Cohen. O Modelo 2 tem Sensibilidade superior, mas quanto a Acurácia os dois modelos empatam. No entanto, são boas métricas para ambos os modelos assim seguiremos com eles, porém agora unindo os dados de treino e de teste.

## Reajuste aos dados completos
Como a previsão para os dados de teste está boa, podemos reajustar e usar o banco de dados completo.

```{r}
final1=df_work %>% 
  extract_workflow("recipe_dummies_logistic") %>% 
  fit(data = df)
final2=df_work %>% 
  extract_workflow("recipe_dummies_logistic_net") %>%
  fit(data = df)

final_predict1 <- final1 %>%  
  predict(new_data = df, type = "prob") %>% 
  bind_cols(df)

final_metrics1 <- final_predict1 %>%
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_0, 
      levels = levels(Survived), 
      threshold = 0.5,
    )
  )
```


```{r}
final1 %>%
  extract_fit_parsnip() %>% 
  tidy() %>%
  mypdf1::pdf1_tbl('Estatísticas do Modelo 1')
```

Ajustando o Modelo 1, com todos os dados ainda obtemos significância em todas as variáveis.


```{r}
class_metrics(final_metrics1, truth=Survived, estimate=.pred) %>% select(-.estimator) %>%
  mypdf1::pdf1_tbl('Métricas de Avaliação do Modelo 1')
```
Em relação as métricas, acontece algo curioso em relação ao modelo ajustado com os dados de teste, em que apenas a Sensibilidade acaba aumentando, mas ainda são bons valores, a Acurácia é de 78,9%.  

```{r}
final_predict2 <- final2 %>%  
  predict(new_data = df, type = "prob") %>% 
  bind_cols(df)

final_metrics2 <- final_predict2 %>%
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_0, 
      levels = levels(Survived), 
      threshold = 0.5,
    )
  )
```


```{r}
final2 %>%
  extract_fit_parsnip() %>% 
  tidy() %>%
  mypdf1::pdf1_tbl('Estatísticas do Modelo 2')
```

Ajustando o Modelo 2, possuímos valores extremamente semelhantes para as estimativas dos $\beta's$, assim as previsões devem permanecer parecidas. 

```{r}
class_metrics(final_metrics1, truth=Survived, estimate=.pred) %>% select(-.estimator) %>%
  mypdf1::pdf1_tbl('Métricas de Avaliação do Modelo 2')
```
Para o modelo 2, aconteceu uma conjuntura  semelhante ao modelo 1, em que as métricas de avaliação acabam diminuindo do Modelo com os Dados de Treino para o Modelo com todos os dados, porém nesse caso nem a Sensibilidade aumentou. No entanto, analisando os valores percebemos que eles são semelhantes aos valores do Modelo 1. 

## Equações dos modelos
`r equatiomatic::extract_eq(final1$fit$fit$fit, wrap = T)` 


# Análise de Influência

Nesta seção será realizada uma busca de observações atípicas no banco de dados, que assim possam estar influenciado a análise, também influenciado pelas junções de tipos realizados anteriomente, assim utilizaremos 5 análises para a verificação de pontos de influência: Análise de Resíduos Deviance, Envelope Simulado, Distância de Cook, Alavancagem e DFFits.

```{r}
ffit1 <- final1$fit$fit$fit
ffit2 <- final2$fit$fit$fit
```


## Resíduos deviances vs indices

```{r}
residuo1 <- residuals(ffit1,type="deviance")
resid1(residuo1,"Resíduos do Modelo 1")
```
Não observa-se algum resíduo fora dos limites especificados, indicando que não exista pontos de influência.

## Envelope Simulado

```{r, results = F, fig.show='hide'}
g1 <- hnp::hnp(ffit1, resid.type="deviance", halfnormal = F)
G1 <- with(g1, data.frame(x, lower, upper, median, residuals))
```

```{r}
G1 %>%
ggplot(aes(x)) +
  geom_point(aes(y = residuals)) +
  geom_line(aes(y = lower)) +
  geom_line(aes(y = upper)) +
  geom_line(aes(y = median), linetype = "dashed")
```
Percebemos que alguns pontos estão fora das bandas simuladas, então devemos procurar por pontos influentes.

## Distância de Cook

```{r}
cook1(ffit1, "Distância do Modelo Gamma") +
    ggrepel::geom_text_repel(aes(label=1:nrow(df)),size=2.8,point.padding = 0.3)
```

Nota-se que principalmente a observação 241 fica fora dos limites estipulados, com achatamento do gráfico da distância de cook, indicam que são potenciais pontos de influência. Dentre os outros pontos fora das bandas simuladas se destacam as observações 272,333,386,397,452,499.

## Alavancagem

```{r}
alavanca1(ffit1) +
    ggrepel::geom_text_repel(aes(label=1:nrow(df)),size=2.8,point.padding = 0.3)
```
Nota-se que alguns pontos ficaram fora dos limites estipulados, sem achatamento do gráfico, mas indicam que são potenciais pontos de influência. Em relação as observações fora dos limites  da distância de cook apenas o 386 está fora, destaca-se também o ponto 617.

## DFFits

```{r}
dffts1(ffit1, "DFFits do Modelo de Regressão Logística")+
    ggrepel::geom_text_repel(aes(label=1:nrow(df)),size=2.8,point.padding = 0.3)
```
Observamos que os pontos 386 e 499 ficam fora dos limites estipulados de maneira mais contundente com as outras observações ficando próximos aos limites, assim são candidatos a pontos de influência.


# Removendo pontos possivelmente influentes
Nesta seção removeremos alguns pontos possivelmente influentes e faremos as analises para verificar se os pontos candidatos são realmente pontos influentes, verificando como fica a equação do modelo e suas métricas.

## Modelo 3 
Neste modelo removemos apenas as observações 241 e 386, foi a observação que mais achatou o gráfico e a que mais se repetiu, respectivamente, assim estimaremos os modelos sem elas.

```{r}
df1 <- rows_delete(df,tibble(PassengerId = c(df %>% mutate(n = 1:nrow(df)) %>% filter(n %in% c(386, 241)) %>% select(PassengerId) %>% unlist() %>% as.vector())))

recipe_titanic_del <- recipe(Survived ~ ., data = df1) %>% 
  update_role(PassengerId, Name, SibSp, Parch, Ticket, Fare, Cabin, Embarked, new_role = "ID") %>% 
  step_dummy(all_nominal_predictors())


del_work=workflow_set(list(recipe_del=recipe_titanic_del),
                     list(logistic=eng_log),cross=T)
final_del=del_work %>% 
  extract_workflow("recipe_del_logistic") %>% 
  fit(data = df1)


final_predict_del <- final_del %>%  
  predict(new_data = df1, type = "prob") %>% 
  bind_cols(df1)

final_metrics_del <- final_predict_del %>%
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_0, 
      levels = levels(Survived), 
      threshold = 0.5,
    )
  )
ffit_del <- final_del$fit$fit$fit
```

```{r}
class_metrics(final_metrics_del, truth=Survived, estimate=.pred) %>% select(-.estimator) %>%
  mypdf1::pdf1_tbl('Métricas de Avaliação do Modelo 3')
```
Nas métricas, nota-se uma ligeira melhora em todas.

### Envelope Simulado
```{r, results = F, fig.show='hide'}
g1 <- hnp::hnp(ffit_del, resid.type="deviance", halfnormal = F)
```


```{r}
G1 <- with(g1, data.frame(x, lower, upper, median, residuals))
G1 %>%
ggplot(aes(x)) +
  geom_point(aes(y = residuals)) +
  geom_line(aes(y = lower)) +
  geom_line(aes(y = upper)) +
  geom_line(aes(y = median), linetype = "dashed")
```
Porém no Envelope Simulado não nota-se uma diferença expressiva para o correspondente do Modelo 1.

### Modelo
```{r}
final_del %>%
  extract_fit_parsnip() %>% 
  tidy() %>%
  mypdf1::pdf1_tbl('Estatísticas do Modelo 3')
```
Continuamos com todas as covariáveis significativas, tem-se pequenas diferenças nos $\beta$ 



## Modelo 4
Neste modelo, teremos uma aplicação mais radical da análise de influência retirando todos os pontos que contiveram pelo menos um *TRUE* (possível ponto de influência), na função `influence.measures` e posteriomente verificando a equação e as métricas.

```{r}
influ <- influence.measures(ffit1)

as.data.frame(influ$is.inf) %>% filter_all(any_vars(. == TRUE)) %>% mypdf1::pdf1_tbl('Diferentes medidas de influência')
```
Assim, removeremos todos os pontos acima, pois já estão filtrados, todos que são candidatos a ponto de influência por alguma métrica.

```{r}
df2 <- rows_delete(df,tibble(PassengerId = c(df %>% mutate(n = 1:nrow(df)) %>% filter(n %in% c(58,60,63,101,118,147,163,166,216,219,229,231,241,244,272,314,323,333,344,358,366,386,397,406,407,440,451,452,459,492.499,526,592,603,609,617,642,658,662,665,670)) %>% select(PassengerId) %>% unlist() %>% as.vector())))


recipe_titanic_del2 <- recipe(Survived ~ ., data = df2) %>% 
  update_role(PassengerId, Name, SibSp, Parch, Ticket, Fare, Cabin, Embarked, new_role = "ID") %>% 
  step_dummy(all_nominal_predictors())


del_work2=workflow_set(list(recipe_del=recipe_titanic_del2),
                     list(logistic=eng_log),cross=T)
final_del2=del_work2 %>% 
  extract_workflow("recipe_del_logistic") %>% 
  fit(data = df2)


final_predict_del2 <- final_del2 %>%  
  predict(new_data = df2, type = "prob") %>% 
  bind_cols(df2)

final_metrics_del2 <- final_predict_del2 %>%
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_0, 
      levels = levels(Survived), 
      threshold = 0.5,
    )
  )
ffit_del2 <- final_del2$fit$fit$fit
```

```{r}
class_metrics(final_metrics_del2, truth=Survived, estimate=.pred) %>% select(-.estimator) %>%
  mypdf1::pdf1_tbl('Métricas de Avaliação do Modelo 4')
```
Percebemos uma melhora em relação ao modelo 3, logo temos uma melhora consideravel ao modelo 1.

### Envelope Simulado
```{r, results = F, fig.show='hide'}
g1 <- hnp::hnp(ffit_del2, resid.type="deviance", halfnormal = F)
G1 <- with(g1, data.frame(x, lower, upper, median, residuals))
```


```{r}
G1 %>%
ggplot(aes(x)) +
  geom_point(aes(y = residuals)) +
  geom_line(aes(y = lower)) +
  geom_line(aes(y = upper)) +
  geom_line(aes(y = median), linetype = "dashed")
```
Reparemos que continua com pontos fora das bandas simuladas, no entanto dimuiu-se a quantidade.

### Modelo
```{r}
final_del2 %>%
  extract_fit_parsnip() %>% 
  tidy() %>%
  mypdf1::pdf1_tbl('Estatísticas do Modelo 4')
```
Continuamos com todas as covariáveis significativas, porém podemos perceber que cada vez o p-valor é menor e a tem-se diferenças claras nos $\beta's$, aumentos significativos matematicamente em Classe 1, Classe 2 e Sexo Feminino, diminuição no $\beta$ do Intercepto.



# Eu sobreviveria ao Titanic?
Teste em todos os Modelos e testando variando a única classe que não temos certeza a classe, assim nos 4 modelos testei as 3 classes.

*Modelo 1*
```{r}
#df[nrow(df) + 1,] <- 
dfn <- df %>% add_row(Survived=NA, Pclass = as.factor(1), Name ='Vítor Bernardo Silveira Pereira', Sex = 'male', Age = 21) %>%
  add_row(Survived=NA, Pclass = as.factor(2), Name ='Vítor Bernardo Silveira Pereira', Sex = 'male', Age = 21) %>% add_row(Survived=NA, Pclass = as.factor(3), Name ='Vítor Bernardo Silveira Pereira', Sex = 'male', Age = 21)
dfn1 <- df1 %>% add_row(Survived=NA, Pclass = as.factor(1), Name ='Vítor Bernardo Silveira Pereira', Sex = 'male', Age = 21) %>%
  add_row(Survived=NA, Pclass = as.factor(2), Name ='Vítor Bernardo Silveira Pereira', Sex = 'male', Age = 21) %>% add_row(Survived=NA, Pclass = as.factor(3), Name ='Vítor Bernardo Silveira Pereira', Sex = 'male', Age = 21)
dfn2 <- df2 %>% add_row(Survived=NA, Pclass = as.factor(1), Name ='Vítor Bernardo Silveira Pereira', Sex = 'male', Age = 21) %>%
  add_row(Survived=NA, Pclass = as.factor(2), Name ='Vítor Bernardo Silveira Pereira', Sex = 'male', Age = 21) %>% add_row(Survived=NA, Pclass = as.factor(3), Name ='Vítor Bernardo Silveira Pereira', Sex = 'male', Age = 21)

eu_m1 <- final1 %>%  
  predict(new_data = dfn, type = "prob") %>% 
  bind_cols(dfn)
eu_m2 <- final2 %>%  
  predict(new_data = dfn, type = "prob") %>% 
  bind_cols(dfn)
eu_m3 <- final_del %>%  
  predict(new_data = dfn1, type = "prob") %>% 
  bind_cols(dfn1)
eu_m4 <- final_del2 %>%  
  predict(new_data = dfn2, type = "prob") %>% 
  bind_cols(dfn2)


eu_m1 <- eu_m1 %>%
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_0, 
      levels = levels(Survived), 
      threshold = 0.5,
    )
  )

eu_m2 <- eu_m2 %>%
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_0, 
      levels = levels(Survived), 
      threshold = 0.5,
    )
  )

eu_m3 <- eu_m3 %>%
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_0, 
      levels = levels(Survived), 
      threshold = 0.5,
    )
  )

eu_m4 <- eu_m4 %>%
  mutate(
    .pred = make_two_class_pred(
      estimate = .pred_0, 
      levels = levels(Survived), 
      threshold = 0.5,
    )
  )
```


```{r}
eu_m1[715:717,] %>% select(.pred, Pclass, Name, Sex, Age)%>%
  mypdf1::pdf1_tbl('Previsão quanto a sobrevivência no Modelo 1')
```

Então, a previsão para o Modelo 1, eu apenas sobreviveria se fosse na Classe 1.

```{r}
eu_m2[715:717,] %>% select(.pred, Pclass, Name, Sex, Age)%>%
  mypdf1::pdf1_tbl('Previsão quanto a sobrevivência no Modelo 2')
```

Então, a previsão para o Modelo 2, eu apenas sobreviveria se fosse na Classe 1, mesma previsão do Modelo anterior.

```{r}
eu_m3[713:715,] %>% select(.pred, Pclass, Name, Sex, Age)%>%
  mypdf1::pdf1_tbl('Previsão quanto a sobrevivência no Modelo 3')
```

Então, a previsão para o Modelo 3, eu apenas sobreviveria se fosse na Classe 1, mesma previsão dos Modelos anteriores.

```{r}
eu_m4[676:678,] %>% select(.pred, Pclass, Name, Sex, Age)%>%
  mypdf1::pdf1_tbl('Previsão quanto a sobrevivência no Modelo 4')
```

Assim, concluímos que de acordo com os modelos testados, eu sobreviveria apenas se embarcasse com a classe 1, no entanto seria o mais provável embarcar com a classe 3, de acordo com a situação financeira.  

# Razão de Chances

Nesta seção iremos verificar algumas razões de chance muito interessante sobre o desastre do Titanic.

*Modelo Geral*

$$ \begin{aligned}
\log\left[ \frac { P( \operatorname{Sobreviver})}{ 1 - P( \operatorname{Sobreviver}) } \right] &= \beta_0 + \beta_{1}(\operatorname{Idade}) + \beta_{2}(\operatorname{Classe_1}) + \beta_{3}(\operatorname{Classe_2})\ + \\&\quad \beta_{4}(\operatorname{Sexo\_feminino})
\end{aligned} $$

Para encontrar razões de chance, iremos realizar o seguinte procedimento:
$$\begin{aligned} e^{\log[\dfrac{ P( \operatorname{Sobreviver})}{ 1 - P( \operatorname{Sobreviver})}]} &= \dfrac{ P( \operatorname{Sobreviver})}{ 1 - P( \operatorname{Sobreviver})}\end{aligned}$$ 

Assim chegamos em uma chance, para chegar em uma razão de chance vamos dividir o modelo, dado que a pessoa que queremos é estimar mulher por uma pessoa que seja homem?

$$\begin{aligned}\dfrac{\dfrac{ P( \operatorname{Sobreviver | mulher})}{ 1 - P( \operatorname{Sobreviver | mulher})}}{\dfrac{ P( \operatorname{Sobreviver | homem})}{ 1 - P( \operatorname{Sobreviver | homem})}} &= \dfrac{e^{\beta_0 + \beta_{1}(\operatorname{Idade}) + \beta_{2}(\operatorname{Classe_1}) + \beta_{3}(\operatorname{Classe_2}  + \beta_{4}(\operatorname{Sexo\_feminino})}}{e^{\beta_0 + \beta_{1}(\operatorname{Idade}) + \beta_{2}(\operatorname{Classe_1}) + \beta_{3}(\operatorname{Classe_2})}} \end{aligned}$$

Aplicando a propriedade da potência que divisão de potencias de bases iguais, temos subtração e assumindo que todas as outras variáveis são constantes chegamos que a razão de chances é:

$$\begin{aligned}\operatorname{RC} &= e^{\beta_{4}}\end{aligned}$$

Assim, podemos calcular a razão de chance para todos os modelos.

Entãos temos que as razões de chance para o modelos 1, 2, 3 e 4 são: `r exp(2.5227809)`, `r exp(2.0965399)`, `r exp(2.5471959)` e `r exp(3.7986619)`. Então de acordo com os modelos ajustados a chance de pessoas do sexo feminino sobreviveram variam de 8.13 a 44.64 vezes maior do que para pessoas do sexo masculino sobreviverem. 

# Conclusão

Observando a equação de todos os modelos, nota-se um padrão, as covariáveis que mais influenciam para sobrevivência são embarcar na primeira classe, ser uma pessoa do sexo feminino e embarcar na segunda classe. Em contrapartida a covariável que menos impacta é a idade, visto que, com maior idade menos provável de sobreviver. Assim, o modelo nos indica que no resgate houve preferência, então, pelas pessoas da primeira classe (mais ricas), mulheres e posteriormente crianças. As mulheres tem incríveis 44 vezes mais chances de sobreviver do que os homens de acordo com o Modelo 4, já segundo esse modelo as pessoas de primeira classe tem 82.5 vezes mais chances de sobreviver que pessoas em terceira classe. Comparando com a segunda classe, as pessoas que embarcaram na primeira classe tem 7.6 vezes mais chances de sobreviver.

Em relação aos modelos, temos que o modelo que sobressai, com as melhores métricas é o modelo 4, consideravelmente a frente do modelo 1 (inicial) e do modelo 3 (com poucas remoções de pontos influentes), percebemos que o modelo 2 é o que se sai pior nessas métricas, também podemos avaliar os critérios de seleção do modelo: 

```{r}
glance(final1) %>% add_row(glance(final_del)) %>% add_row(glance(final_del2)) %>%
  mypdf1::pdf1_tbl('Critérios de Seleção do Modelo para as Regressões Logisticas')
```
Assim, percebemos que nos principais critérios de seleção AIC e BIC, o modelo 4, tem medidas consideravelmente menores e melhores. Para a Regressão Logística - GLM NET, temos:

```{r}
glance(final2) %>%
  mypdf1::pdf1_tbl('Critérios de Seleção do Modelo - GLMNET')
```
Assim comparando esses critérios com o da Tabela acima, podemos perceber que os outros modelos são superiores. Então para a seleção do melhor modelo temos que levar em consideração alguns fatores, que o Modelo 4 foi o melhor modelo no geral, em métricas de acurácia e critérios de seleção, logo o melhor modelo para previsão dos dados. 

No entanto, o Modelo 1, com todos os dados pode ser o mais correto inferencialmente, pois seria o mais representativo em relação a população, também pode estar sendo mais cauteloso quanto ao pressuposto de amostra aleatória, o que no Modelo 4 quebramos com a remoção das observações.

Tendo essas observações em vista e sem um estudo mais aprofundado para a remoção de pontos influentes, a escolha para o Modelo 4, seria para um modelo com melhor capacidade preditiva e a escolha para o Modelo 1, seria para um modelo com melhores conclusões inferenciais.